# Kafka简介

## 1、 简介

&emsp;&emsp;`Apache Kafka` 是一个开源分布式事件流平台，被数千家公司用于高性能数据管道、流分析、数据集成和任务关键型应用程序。

&emsp;&emsp;超过**80%的财富100强公司**信任并使用Kafka。

- **核心能力：**

  - 高吞吐量：使用延迟低至 2 毫秒的计算机群集以网络有限的吞吐量传递消息。
  - 可伸缩：将生产群集扩展到多达 1000 个代理、每天数万亿条消息、PB 级数据、数十万个分区。弹性扩展和收缩存储和处理。
  - 永久存储：将数据流安全地存储在分布式、持久、容错的群集中。
  - 高可用性：在可用性区域上高效地扩展群集，或跨地理区域连接单独的群集。

- **生态系统：**

  - 内置流处理：使用事件时间和精确一次处理，使用联接、聚合、筛选器、转换等处理事件流。
  - 几乎可以连接到任何内容：Kafka 的开箱即用 Connect 接口集成了数百个事件源和事件接收器，包括 Postgres、JMS、Elasticsearch、AWS S3 等。
  - 客户端库：使用各种编程语言读取、写入和处理事件流。
  - 大型生态系统开源工具：开源工具的大型生态系统：利用大量社区驱动的工具。

- **信任和易用性：**

  - 关键任务：通过有保证的排序、零消息丢失和高效的一次性处理，支持任务关键型使用案例。
  - 受到数千家组织的信赖：成千上万的组织使用Kafka，从互联网巨头到汽车制造商再到证券交易所。超过500万次独特的终身下载。
  - 庞大的用户社区：Kafka是Apache软件基金会最活跃的五个项目之一，在全球有数百个聚会。
  - 丰富的在线资源：丰富的文档、在线培训、指导教程、视频、示例项目、堆栈溢出等。

   





## 2、介绍

### 2.1、什么是事件流式处理？

&emsp;&emsp;事件流是人体中枢神经系统的数字等效物。它是"永远在线"的世界的技术基础，在这个世界中，企业越来越多地被软件定义和自动化，软件的用户更多的是软件。

&emsp;&emsp;从技术上讲，事件流是以事件流的形式从事件源（如数据库，传感器，移动设备，云服务和软件应用程序）实时捕获数据的做法;持久存储这些事件流以供以后检索;实时和回顾性地操作、处理和响应事件流;并根据需要将事件流路由到不同的目标技术。因此，事件流可确保数据的连续流动和解释，以便正确的信息在正确的时间出现在正确的位置。



### 2.2 我可以使用事件流做什么？

&emsp;&emsp;事件流适用于众多行业和组织[的各种用例](https://kafka.apache.org/powered-by)。它的许多例子包括：

- 实时处理付款和金融交易，例如在证券交易所、银行和保险中。
- 实时跟踪和监控汽车、卡车、车队和货物，例如在物流和汽车行业。
- 持续捕获和分析来自物联网设备或其他设备（如工厂和风电场）的传感器数据。
- 收集并立即响应客户交互和订单，例如在零售，酒店和旅游业以及移动应用程序中。
- 监测医院护理中的患者并预测病情变化，以确保在紧急情况下及时治疗。
- 连接、存储和提供由公司不同部门生成的数据。
- 作为数据平台、事件驱动型体系结构和微服务的基础。



### 2.3 Apache Kafka®是一个事件流媒体平台。那是什么意思？

&emsp;&emsp;Kafka 结合了三个关键功能，因此您可以使用经过实战检验的解决方案实现端到端事件流的[用例](https://kafka.apache.org/powered-by)：

1. **发布**（写入）和**订阅**（读取）事件流，包括从其他系统连续导入/导出数据。
2. 持久可靠地**存储**事件流，只要您愿意。
3. 在事件发生时或事后**处理**事件流。

&emsp;&emsp;所有这些功能都是以分布式、高度可扩展、弹性、容错和安全的方式提供的。Kafka 可以部署在裸机硬件、虚拟机和容器上，也可以部署在本地和云中。您可以选择自我管理 Kafka 环境和使用各种供应商提供的完全托管服务。



### 2.4 简而言之，卡夫卡是如何工作的？

&emsp;&emsp;Kafka是一个分布式系统，由通过高性能[TCP网络协议](https://kafka.apache.org/protocol.html)进行通信的**服务器**和**客户端**组成。它可以部署在内部部署和云环境中的裸机硬件、虚拟机和容器上。

&emsp;&emsp;**服务器**：Kafka 作为一个或多个服务器的群集运行，这些服务器可以跨越多个数据中心或云区域。其中一些服务器形成存储层，称为代理。其他服务器运行[Kafka Connect](https://kafka.apache.org/documentation/#connect)以连续导入和导出数据作为事件流，以将Kafka与您现有的系统（如关系数据库以及其他Kafka集群）集成。为了让您能够实现任务关键型用例，Kafka 集群具有高度的可扩展性和容错能力：如果其任何服务器发生故障，其他服务器将接管其工作，以确保连续运行而不会丢失任何数据。

&emsp;&emsp;**客户端**：它们允许您编写分布式应用程序和微服务，这些应用程序和微服务以并行、大规模和容错的方式读取、写入和处理事件流，即使在网络问题或机器故障的情况下也是如此。Kafka附带了一些这样的客户端，这些客户端由Kafka社区提供的[数十个客户端](https://cwiki.apache.org/confluence/display/KAFKA/Clients)增强：客户端可用于Java和Scala，包括更高级别的[Kafka Streams](https://kafka.apache.org/documentation/streams/)库，用于Go，Python，C / C++以及许多其他编程语言以及REST API。



### 2.5 主要概念和术语

&emsp;&emsp;**事件**记录了世界或您的业务中"发生某些事情"的事实。在文档中也称为记录或消息。当您向 Kafka 读取或写入数据时，您以事件的形式执行此操作。从概念上讲，事件具有键、值、时间戳和可选的元数据标头。下面是一个示例事件：

- 事件键："爱丽丝"
- 事件价值："已向 Bob 支付了 200 美元"
- 事件时间戳："2020 年 6 月 25 日下午 2：06 .m。

&emsp;&emsp;**创建者**是将事件发布（写入）到 Kafka 的客户端应用程序，而**使用者**是订阅（读取和处理）这些事件的客户端应用程序。在Kafka中，生产者和消费者是完全脱钩的，彼此不可知，这是实现Kafka众所周知的高可扩展性的关键设计元素。例如，生产者永远不需要等待消费者。Kafka 提供了各种[保证](https://kafka.apache.org/documentation/#semantics)，例如能够精确地处理一次事件。

&emsp;&emsp;活动被组织并持久存储在**主题**中。非常简化，主题类似于文件系统中的文件夹，事件是该文件夹中的文件。示例主题名称可以是"付款"。Kafka 中的主题始终是多生产者和多订阅者：一个主题可以有零个、一个或多个向其写入事件的创建者，也可以有零个、一个或多个订阅这些事件的使用者。主题中的事件可以根据需要随时读取 — 与传统消息传递系统不同，事件在使用后不会被删除。相反，您可以通过每个主题的配置设置来定义 Kafka 应将事件保留多长时间，之后旧事件将被丢弃。Kafka的性能在数据大小方面实际上是恒定的，因此长时间存储数据是完全可以的。

&emsp;&emsp;主题是**分区的**，这意味着一个主题分布在位于不同Kafka代理上的许多"存储桶"上。数据的这种分布式放置对于可伸缩性非常重要，因为它允许客户端应用程序同时从/向多个代理读取和写入数据。将新事件发布到主题时，它实际上会追加到该主题的某个分区。具有相同事件密钥的事件（例如，客户或车辆 ID）将写入同一分区，并且 Kafka [保证](https://kafka.apache.org/documentation/#semantics)给定主题分区的任何使用者将始终以与写入时完全相同的顺序读取该分区的事件。

![img](https://kafka.apache.org/images/streams-and-tables-p1_p4.png)

图：此示例主题有四个分区 P1–P4。两个不同的生产者客户端通过网络将事件写入主题的分区，从而彼此独立地将新事件发布到主题。具有相同键（在图中用它们的颜色表示)的事件将写入同一分区。请注意，如果适用，两个创建者都可以写入同一分区。



&emsp;&emsp;为了使您的数据具有容错能力和高可用性，可以**复制**每个主题，甚至可以跨地理区域或数据中心复制每个主题，以便始终有多个代理拥有数据副本，以防万一出现问题，您希望对代理进行维护，等等。常见的生产设置是复制因子 3，即始终有三个数据副本。此复制是在主题分区级别执行的。

&emsp;&emsp;该引物应足以进行介绍。如果您有兴趣，文档的"[设计](https://kafka.apache.org/documentation/#design)"部分将详细解释Kafka的各种概念。



### 2.6 卡夫卡接口

除了用于管理和管理任务的命令行工具外，Kafka 还有五个用于 Java 和 Scala 的核心 API：

- [管理 API](https://kafka.apache.org/documentation.html#adminapi)，用于管理和检查主题、代理和其他 Kafka 对象。
- [创建者 API](https://kafka.apache.org/documentation.html#producerapi)，用于将事件流发布（写入）到一个或多个 Kafka 主题。
- [使用者 API](https://kafka.apache.org/documentation.html#consumerapi)，用于订阅（读取）一个或多个主题并处理向它们生成的事件流。
- [Kafka Streams API](https://kafka.apache.org/documentation/streams)，用于实现流处理应用程序和微服务。它提供了更高级的函数来处理事件流，包括转换、有状态操作（如聚合和联接）、窗口化、基于事件时间的处理等。从一个或多个主题读取输入，以便生成一个或多个主题的输出，从而有效地将输入流转换为输出流。
- [Kafka Connect API](https://kafka.apache.org/documentation.html#connect)，用于构建和运行可重用的数据导入/导出连接器，这些连接器使用（读取）或生成（写入）来自外部系统和应用程序的事件流，以便它们可以与 Kafka 集成。例如，与关系数据库（如 PostgreSQL）的连接器可能会捕获对一组表所做的每个更改。但是，在实践中，通常不需要实现自己的连接器，因为 Kafka 社区已经提供了数百个即用型连接器。



### 2.7 如何学习使用

- 若要获取 Kafka 的实践经验，请遵循[快速入门](https://kafka.apache.org/quickstart)。
- 要更详细地了解 Kafka，请阅读[文档](https://kafka.apache.org/documentation/)。您还可以选择[卡夫卡的书籍和学术论文](https://kafka.apache.org/books-and-papers)。
- 浏览[用例](https://kafka.apache.org/powered-by)，了解我们全球社区中的其他用户如何从Kafka中获得价值。
- 加入[当地的卡夫卡聚会小组](https://kafka.apache.org/events)，[观看卡夫卡峰会的演讲，卡](https://kafka-summit.org/past-events/)夫卡社区的主要会议。









